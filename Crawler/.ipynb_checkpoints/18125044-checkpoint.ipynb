{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import helpful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import *\n",
    "base = 'https://vnexpress.net/'\n",
    "driver = webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define categories\n",
    "VnExpress has many categories, we must define the categories to be crawled.\n",
    "In this assignment, I define:\n",
    "- Thoi su (news)\n",
    "- The gioi (the world)\n",
    "- Kinh doanh (business)\n",
    "- Giai tri (entertainment)\n",
    "- The thao (sports)\n",
    "- Phap luat (laws)\n",
    "- Giao duc (education)\n",
    "- Suc khoe (health)\n",
    "- Doi song (life)\n",
    "- Du lich (travelling)\n",
    "- Khoa hoc (science)\n",
    "- So hoa (technology)\n",
    "- Oto xe may (automobiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = ['thoi-su','the-gioi','kinh-doanh', 'giai-tri', 'the-thao', 'phap-luat', 'giao-duc', 'suc-khoe', 'doi-song', 'du-lich', 'khoa-hoc', 'so-hoa', 'oto-xe-may']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day gap\n",
    "The function calculating the day gap between the given <em>'date'</em> and today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap(date):\n",
    "    now = datetime.datetime.today()\n",
    "    date = datetime.datetime.strptime(date, '%d/%m/%Y')\n",
    "    delta = now - date\n",
    "    return delta.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the day\n",
    "The function getting the date from given source page, <em>url</em>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(url):\n",
    "    driver.get(url)\n",
    "    page = bs(driver.page_source, 'html.parser')\n",
    "    content = page.find_all('span', {'class' : 'date'})\n",
    "    if len(content) > 0:\n",
    "        info = content[0].text.strip()\n",
    "        info = info.split(',')\n",
    "        while info[1][0] == ' ':\n",
    "            info[1] = info[1][1:]\n",
    "        #Due to the format in VnExpress, the date is the second part\n",
    "        return info[1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the titles\n",
    "The function getting all titles available in the given page, <em>url</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url):\n",
    "    titles = []\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    page = bs(driver.page_source, 'html.parser')\n",
    "    block = page.find_all(class_='title-news')\n",
    "    \n",
    "    for element in block:\n",
    "        title = element.find('a')\n",
    "        if title.get('target', '') == '' and title['href'][0] != '/':\n",
    "            date = getDate(title['href'])\n",
    "            if date is not None:\n",
    "                g = gap(date)\n",
    "                if g <= 7:\n",
    "                    titles.append(title.text.strip())\n",
    "                else:\n",
    "                    return titles, None\n",
    "    return titles, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "The main flow of the program.\n",
    "- Go to all categories defined above\n",
    "- For each categories, try to get all the titles in the page.\n",
    "- If can go on, try to go to next page. Go on = the last title to be retrieved is published within a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for category in cate:\n",
    "    url = base + category\n",
    "    title, legal = crawl(url)\n",
    "    titles.extend(title)\n",
    "    next_page = 2\n",
    "    while legal is not None :\n",
    "        URL = url + '-p' + str(next_page)\n",
    "        title, legal = crawl(URL)\n",
    "        titles.extend(title)\n",
    "        next_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('18125044.txt', 'w') as f:\n",
    "    for title in titles:\n",
    "        f.write(title + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
