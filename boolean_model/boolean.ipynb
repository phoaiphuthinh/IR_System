{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "# Step 0: Scan all text files\n",
    "paths = glob.glob('data/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(vocab, word):\n",
    "    index = vocab.get(word, len(vocab))\n",
    "    if index == len(vocab):\n",
    "        vocab[word] = index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "dictionary = dict()\n",
    "for path in paths:\n",
    "    # Read file\n",
    "    f = open(path, encoding=\"utf8\")\n",
    "    str = f.read()\n",
    "    words = re.findall(r\"[\\w']+\", str)\n",
    "    words = [getIndex(dictionary, word.lower()) for word in words]\n",
    "    contents.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc = np.zeros((1, len(dictionary) * len(paths)))\n",
    "lf = lambda i, x: list(map(lambda num: num * len(paths) + i, x))\n",
    "index = list(map(lambda x: lf(x[0], x[1]), list(enumerate(contents))))\n",
    "index = functools.reduce(operator.iconcat, index, [])\n",
    "np.put(term_doc, index, 1)\n",
    "term_doc = np.reshape(term_doc, (len(dictionary), len(paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'Mai' AND 'ChÃ¢u'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' X   &   X '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = re.findall(r\"\\'[\\w\\s\\d]+\\'\", query)\n",
    "query = re.sub(r\"\\'[\\w\\s\\d]+\\'\", \" X \", query)\n",
    "query = re.sub(r\"AND\", \" & \", query)\n",
    "query = re.sub(r\"OR\", \" | \", query)\n",
    "query = re.sub(r\"XOR\", \" ^ \", query)\n",
    "query = re.sub(r\"NOT\", \" - \", query)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(map(lambda x : x[1:-1], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = []\n",
    "for words in x:\n",
    "    word = words.split()\n",
    "    tmp = np.ones(len(paths))\n",
    "    for w in word:\n",
    "        if w.lower() in dictionary:\n",
    "            tmp = np.logical_and(tmp, term_doc[dictionary[w.lower()], :])\n",
    "        else:\n",
    "            tmp = np.zeros(len(paths))\n",
    "    op.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False,  True, False, False, False,\n",
       "        False, False]),\n",
       " array([False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False,  True, False, False,\n",
       "        False, False,  True, False, False, False, False, False,  True,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toRPN(query):\n",
    "    output = []\n",
    "    oper = []\n",
    "    cnt = 0\n",
    "    for token in query:\n",
    "        if token == 'X':\n",
    "            output.append(cnt)\n",
    "            cnt += 1\n",
    "        elif token == '(':\n",
    "            oper.append(token)\n",
    "        elif token == ')':\n",
    "            while len(oper) > 0 and oper[-1] != '(':\n",
    "                output.append(oper.pop())\n",
    "            oper.pop()\n",
    "        else:\n",
    "            while len(oper) > 0 and oper[-1] != '(':\n",
    "                output.append(oper.pop())\n",
    "            oper.append(token)\n",
    "    while len(oper) > 0:\n",
    "        output.append(oper.pop())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(query):\n",
    "    if len(query) == 1:\n",
    "        return op[query[0]]\n",
    "    tmp = np.ones(len(paths))\n",
    "    st = []\n",
    "    for x in query:\n",
    "        if isinstance(x, int):\n",
    "            st.append(op[x])\n",
    "        elif x == '-':\n",
    "            opp = st.pop()\n",
    "            new_op = np.logical_not(opp)\n",
    "            st.append(new_op)\n",
    "        else:\n",
    "            op1 = st.pop()\n",
    "            op2 = st.pop()\n",
    "            if x == '&':\n",
    "                new_op = np.logical_and(op1, op2)\n",
    "            elif x == '|':\n",
    "                new_op = np.logical_or(op1, op2)\n",
    "            else:\n",
    "                new_op = np.logical_xor(op1, op2)\n",
    "            st.append(new_op)\n",
    "    return st.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_query = toRPN(query)\n",
    "res = calculate(bool_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = np.argwhere(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data17.txt\n",
      "data/data37.txt\n"
     ]
    }
   ],
   "source": [
    "for index in art:\n",
    "    print(paths[index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
